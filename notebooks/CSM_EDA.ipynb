{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eda6b90",
   "metadata": {},
   "source": [
    "Introduction: Introduce the data we use. Summarize the problems with the data sets and our approach to solve those problem. State the question that we are trying to answer (to predict if a provider is fraud)\n",
    "Import libraries, packages, etc. and load the data, with some general info of the data (head, info, describe etc)\n",
    "Check if some column/row contains no valuable info to drop them (missing value summary chart)\n",
    "Deal with LEIE file to get the list of fraud NPI (name/address match if possible), call this df_label\n",
    "Join df_label with data set B, D and DME on NPI and aggregate\n",
    "Remove unneccessary columns, maybe we can try PCA a little bit?\n",
    "Top cities, states, general, specialty etc. involve in fraud\n",
    "Histogram on each features to see if there is any difference between non-fraud and fraud?\n",
    "Features selection (I'm not sure how we should proceed?)\n",
    "Plot relationship between selected features and potential_fraud\n",
    "Conclusion/comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbfb744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775fcfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "dat_B = pd.read_csv(os.path.join(folder_path, 'CMS', 'formB_MUP_PHY_R21_P04_V10_D19_Prov_Svc-001.csv'), encoding = \"ISO-8859-1\")\n",
    "dat_D = pd.read_csv(os.path.join(folder_path, 'CMS', 'formD_MUP_DPR_RY21_P04_V10_DY19_NPIBN_1-002.csv'), encoding = \"ISO-8859-1\")\n",
    "dat_dme = pd.read_csv(os.path.join(folder_path, 'CMS', 'mup_dme_ry21_p05_v10_dy19_prvhpr_0.csv'), encoding = \"ISO-8859-1\")\n",
    "label_df = pd.read_csv(os.path.join(folder_path, 'LEIE', 'UPDATED.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec042c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary of missing value\n",
    "dat_B.isna().sum()\n",
    "dat_D.isna().sum()\n",
    "dat_dme.isna().sum()\n",
    "label_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3144b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate data\n",
    "dat_B_agg = dat_B.groupby(['Rndrng_NPI','Rndrng_Prvdr_Ent_Cd', 'Rndrng_Prvdr_Cntry']).agg(\n",
    "                                                   {'Tot_Srvcs':['sum', 'mean', 'median', np.std, 'min', 'max'],\n",
    "                                                    'Tot_Benes':['sum', 'mean', 'median', np.std, 'min', 'max'],\n",
    "                                                    'Tot_Bene_Day_Srvcs':['sum', 'mean', 'median', np.std, 'min', 'max'],\n",
    "                                                    'Avg_Sbmtd_Chrg':['sum', 'mean', 'median', np.std, 'min', 'max'],\n",
    "                                                    'Avg_Mdcr_Pymt_Amt': ['sum', 'mean', 'median', np.std, 'min', 'max']\n",
    "                                                 })\n",
    "dat_B_agg.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f9e12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_D_agg = dat_D.groupby(['Prscrbr_NPI','Prscrbr_Type']).agg(\n",
    "                                                  {'Tot_Benes':['sum', 'mean', 'median', np.std, 'min', 'max'],\n",
    "                                                   'Tot_Clms':['sum', 'mean', 'median', np.std, 'min', 'max'],\n",
    "                                                   'Tot_30day_Fills':['sum', 'mean', 'median', np.std, 'min', 'max'],\n",
    "                                                   'Tot_Day_Suply':['sum', 'mean', 'median', np.std, 'min', 'max'],\n",
    "                                                   'Tot_Drug_Cst': ['sum', 'mean', 'median', np.std, 'min', 'max']\n",
    "                                                  })\n",
    "dat_D_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ad0894",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_dme_agg = dat_dme.groupby(['Rfrg_NPI',]).agg({'Tot_Suplrs':['sum', 'mean', 'median', np.std, 'min', 'max'],\n",
    "                                                       'Tot_Suplr_Benes':['sum', 'mean', 'median', np.std, 'min', 'max'],\n",
    "                                                       'Tot_Suplr_Clms':['sum', 'mean', 'median', np.std, 'min', 'max'],\n",
    "                                                       'Tot_Suplr_Srvcs':['sum', 'mean', 'median', np.std, 'min', 'max'],\n",
    "                                                       'Avg_Suplr_Mdcr_Pymt_Amt':['sum', 'mean', 'median', np.std, 'min', 'max'],\n",
    "                                                       'Avg_Suplr_Mdcr_Stdzd_Amt': ['sum', 'mean', 'median', np.std, 'min', 'max']\n",
    "                                                 })\n",
    "                                                                                    \n",
    "dat_dme_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa8694",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge data based on NPI\n",
    "merged_d = dat_dme_agg.reset_index().merge(dat_D_agg, how='inner', left_on=['Rfrg_NPI'], right_on=['Prscrbr_NPI'])\n",
    "merged_d = merged_d.merge(dat_B_agg, how='inner', left_on='Rfrg_NPI', right_on='Rndrng_NPI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8d7bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing the label data\n",
    "df_label_fraud = label_df[label_df['NPI'] != 0] #get all rows that have nonzero NPI\n",
    "df_label_fraud = df_label_fraud[~df_label_fraud.index.duplicated(keep='first')].reset_index('NPI') #remove duplicated NPI\n",
    "pd.Series(df_label_fraud.NPI).is_unique #check if the NPI is indeed unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cde1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 10 States involving in Fraud\n",
    "sns.set(rc={'figure.figsize':(12,8)},style='white')\n",
    "\n",
    "ax=sns.countplot(x='STATE',data=df_label_fraud\n",
    "              ,order=df_label_fraud.STATE.value_counts().iloc[:10].index)\n",
    "\n",
    "plt.title('Top-10 States involved in Healthcare Fraud')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95028a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 10 Cities involving in Fraud\n",
    "df_label_fraud['city'] = df_label_fraud['CITY'] + ', ' + df_label_fraud['STATE'] #we add state to city to avoid problem of same city name for different states\n",
    "print(df_label_fraud.city.value_counts())\n",
    "#sns.set(rc={'figure.figsize':(12,8)},style='white')\n",
    "ax=sns.countplot(x='city',data=df_label_fraud\n",
    "             ,order=df_label_fraud.city.value_counts().iloc[:10].index)\n",
    "\n",
    "plt.title('Top-10 Cities involved in Healthcare Fraud')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbfa8ac",
   "metadata": {},
   "source": [
    "We see that Miami, FL is the city with most healthcare fraud although Florida is only at 3rd place in the list of states with most fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3670bfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 10 generals involving in Fraud\n",
    "sns.set(rc={'figure.figsize':(12,8)},style='white')\n",
    "\n",
    "ax=sns.countplot(x='GENERAL',data=df_label_fraud\n",
    "              ,order=df_label_fraud.GENERAL.value_counts().iloc[:10].index)\n",
    "\n",
    "plt.title('Top-10 Generals involved in Healthcare Fraud')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea3e4ae",
   "metadata": {},
   "source": [
    "The number of fraud in IND- LIC HC SERV PRO and PHYSICIAN (MD, DO) are outstanding compared to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7897c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe, named df_label, with first column is NPI and second column is Potential_Fraud \n",
    "label = df_label_fraud['NPI']\n",
    "df_label = {\"NPI\":[],\"Potential_Fraud\":[]}\n",
    "for i in label:\n",
    "    df_label['NPI'].append(i) \n",
    "    df_label['Potential_Fraud'].append('Yes')\n",
    "df_label = pd.DataFrame(df_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c1cf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking variance of average amount charged based on type of service\n",
    "dat_B.groupby('HCPCS_Cd').agg({'Avg_Sbmtd_Chrg':np.mean}).sort_values('Avg_Sbmtd_Chrg')\n",
    "df_grouped = dat_B.groupby([, 'Rndrng_NPI']).agg({'Avg_Sbmtd_Chrg':np.mean}).sort_values('Avg_Sbmtd_Chrg')\n",
    "df_test = dat_B.groupby(['HCPCS_Cd']).agg({'Avg_Sbmtd_Chrg': lambda x: np.std(x)})\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.ma.core import std\n",
    "plt.hist(df_test['Avg_Sbmtd_Chrg'], bins = 50)\n",
    "plt.show()\n",
    "df_test_greater_than_50 = df_test[df_test['Avg_Sbmtd_Chrg'] > np.mean(df_test['Avg_Sbmtd_Chrg'])]\n",
    "plt.hist(df_test_greater_than_50['Avg_Sbmtd_Chrg'])\n",
    "plt.show()\n",
    "df_test_greater_than_50.sort_values('Avg_Sbmtd_Chrg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9924aee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "leie = label_df\n",
    "#mandatory minimum penalty based on offense category\n",
    "minimum_exclusion_periods = { \n",
    "    '1128a1':5, #Conviction of program-related crimes. Minimum Period: 5 years\n",
    "    '1128a2':5, #Conviction relating to patient abuse or neglect. Minimum Period: 5 years\n",
    "    '1128a3':5, #Felony conviction relating to health care fraud. Minimum Period: 5 years\n",
    "    '1128b4':np.nan, #License revocation, suspension, or surrender. Minimum Period: Period imposed by the state licensing authority.    \n",
    "    '1128b7':np.nan, #Fraud, kickbacks, and other prohibited activities. Minimum Period: None\n",
    "    '1128c3gi':10, #Conviction of second mandatory exclusion offense. Minimum Period: 10 years\n",
    "    '1128c3gii':100 #Conviction of third or more mandatory exclusion offenses. Permanent Exclusion\n",
    "}\n",
    "exclusion_codes = ['1128a1', '1128a2', '1128a3', '1128b4', '1128b7', '1128c3gi', '1128c3gii']\n",
    "filtered_leie = leie[leie.EXCLTYPE.isin(exclusion_codes)]\n",
    "filtered_leie.shape\n",
    "filtered_leie.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed1b5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to time\n",
    "filtered_leie['EXCLDATE'] = pd.to_datetime(filtered_leie.EXCLDATE, format='%Y%m%d') #most important value\n",
    "filtered_leie['WAIVERDATE'] = pd.to_datetime(filtered_leie.WAIVERDATE, format='%Y%m%d', errors='coerce')\n",
    "filtered_leie['REINDATE'] = pd.to_datetime(filtered_leie.REINDATE, format='%Y%m%d', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45044328",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique `WAIVERDATE` values: \", len(filtered_leie['WAIVERDATE'].unique()))\n",
    "print(\"Unique `REINDATE` values: \", len(filtered_leie['REINDATE'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac27e998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping the penalty to the minimum exclusions period, placing minimum exclusions on their own col\n",
    "\n",
    "filtered_leie['MIN_EXCLUSION_PERIOD'] = filtered_leie['EXCLTYPE'].map(minimum_exclusion_periods)\n",
    "filtered_leie.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf32fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_leie['END_EXCLDATE'] = filtered_leie.EXCLDATE.dt.year + filtered_leie.MIN_EXCLUSION_PERIOD\n",
    "filtered_leie.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62587444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_exclusion_end(exclusion_date, end_year):\n",
    "    month = exclusion_date.month\n",
    "    \n",
    "\n",
    "    if month > 6:\n",
    "        return end_year + 1\n",
    "    else:\n",
    "        return end_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb7466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the function that calculates end dates\n",
    "\n",
    "filtered_leie['END_EXCLDATE'] = filtered_leie[[\"EXCLDATE\",\"END_EXCLDATE\"]].apply(lambda x: calculate_exclusion_end(*x), axis=1)\n",
    "filtered_leie.columns\n",
    "filtered_leie = filtered_leie[['NPI','ZIP','EXCLTYPE',\n",
    "       'EXCLDATE', 'REINDATE', 'WAIVERDATE', 'WVRSTATE',\n",
    "       'MIN_EXCLUSION_PERIOD', 'END_EXCLDATE']]\n",
    "filtered_leie\n",
    "filtered_leie = filtered_leie[filtered_leie.NPI != 0]\n",
    "labeled_data = pd.merge(merged_d, filtered_leie, on='NPI',how='left') #add a column to the data which contain the fraud information.\n",
    "labeled_data['TARGET'] = '0'\n",
    "labeled_data['START_EXCLDATE'] = labeled_data['EXCLDATE'].dt.year\n",
    "labeled_data['DATA_YEAR'] = 2019\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392f3069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_labels(start_exc, data_yr):\n",
    "    if start_exc > data_yr:\n",
    "        return 'FRAUD'\n",
    "    else:\n",
    "        return 'NOT_FRAUD'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9135a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the fraud labeling function to datasets\n",
    "labeled_data['TARGET'] = labeled_data[[\"START_EXCLDATE\",\"DATA_YEAR\"]].apply(lambda x: make_labels(*x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0387710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unneeded columns\n",
    "columns_to_drop = [ 'EXCLTYPE','EXCLDATE','REINDATE','WAIVERDATE',\n",
    "                   'WVRSTATE','MIN_EXCLUSION_PERIOD','END_EXCLDATE',\n",
    "                   'START_EXCLDATE', 'DATA_YEAR','ZIP']\n",
    "\n",
    "labeled_data.drop(columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1295f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding\n",
    "partb_category_columns = ['provider_type', 'nppes_provider_gender']\n",
    "partd_category_columns = ['specialty_description']\n",
    "dmepos_category_columns = ['REFERRING_PROVIDER_GENDER', 'REFERRING_PROVIDER_TYPE']\n",
    "combined_category_columns = ['provider_type', 'nppes_provider_gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078f1c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features selection\n",
    "#create heatmap on data set B\n",
    "sns.heatmap(dat_B.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf8198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We drop columns with high correlation since it's not helpful for our model\n",
    "to_drop_B = ['Tot_Bene_Day_Srvcs', 'Avg_Mdcr_Alowd_Amt', 'Avg_Mdcr_Pymt_Amt', 'Avg_Mdcr_Stdzd_Amt']\n",
    "dat_B = dat_B.drop(labels = to_drop_B, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3883213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create heatmap on data set D\n",
    "sns.heatmap(dat_D.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec43907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We drop columns with high correlation since it's not helpful for our model\n",
    "to_drop_D = ['Prscrbr_Last_Org_Name', 'Prscrbr_First_Name', 'GE65_Tot_Clms', 'GE65_Tot_30day_Fills', 'GE65_Tot_Drug_Cst', 'GE65_Tot_Day_Suply', 'GE65_Tot_Benes']\n",
    "dat_D = dat_D.drop(labels = to_drop_D, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4169dafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create heat map on DME\n",
    "sns.heatmap(dat_dme.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ade9205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We drop columns with high correlation\n",
    "to_drop_dme = ['Avg_Suplr_Mdcr_Pymt_Amt', 'Avg_Suplr_Mdcr_Stdzd_Amt']\n",
    "dat_dme = dat_dme.drop(labels = to_drop_dme, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
